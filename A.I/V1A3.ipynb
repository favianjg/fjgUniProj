{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Allgemeine Fragen zur Evaluation eines Klassifikators:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Welche Klassifikationsfehlerwahrscheinlichkeit erhält man, wenn man einen k-NN-Klassifikator für k = 1 auf der gespeicherten Lern-Daten-Menge X testet?__\n",
    "\n",
    "Wird ein k-NN-Klassifikator für k=1 getestet, so erhält man eine Klassifikationesfehlerwahrscheinlichkeit von 0% [ siehe Aufgabe 2d) A-Posteriori Class Distribution]\n",
    "\n",
    "__Bedeutet dies, dass der k-NN-Klassifikator auch auf neuen Datenvektoren x (welche nicht gespeichert sind) immer korrekt klassifiziert?__\n",
    "\n",
    "Nein, dies bedeutet lediglich, dass der k-NN-Klassifikator zu wenige Datenpunkte betrachtet um eine mögliche Falschklassifizierung berechnen zu können, bzw dass die Lern- und Testdaten zu ähnlich oder gar gleich waren und der Klassifikator auf den vermeintlich neuken Datenvektor eingelernt wurde.\n",
    "\n",
    "__Was kann man tun um einen realistischen Schätzwert des Generalisierungsfehlers\n",
    "(d.h. der Klassifikationsfehlerwahrscheinlichkeit für neue Daten) zu erhalten ?__\n",
    "\n",
    "Für k muss ein geeigneter Wert, welcher nicht zu groß aber auch nicht zu klein ist gewählt werden. Außerdem müssen Validierungs- und Trainingsdaten strikt getrennt werden. Je mehr Validierungsdaten man verwendet, desto realistischer wird der Schätzwert des Generalisierungsfehlers, desto weniger Trainingsdaten sind jedoch vorhanden.\n",
    "\n",
    "__Erklären Sie kurz den Begriff Kreuzvalidierung und ihren Zweck! Lesen Sie hierzu\n",
    "im Skript (siehe Folien zu Kapitel 2).__\n",
    "\n",
    "Bei der Kreuzvalidierung verwendet immer einen Teil der Testdaten zum Validieren, jedoch nie die gesamten Test-Daten in einem Durchlauf. Hierfür werden die Test-Daten in S-Teile geteilt. Dann wird das Modell S mal mit den Test-Daten trainiert, wobei jedesmal ein (anderer) Teil der Daten zur Validierung zurückbehalten wird. Am Ende erhält man den den Generalisierungsfehler durch mitteln der Ergebnisse aller S Durchgänge.\n",
    "Der Zweck dieser Methode ist, dass man alle Daten sowohl zum Testen, als auch zum Validieren verwenden kann. Je größer S gewählt wird, desto mehr der Daten können zum Trainieren verwendet werden, die Anzahl der Durchgänge erhöht sich jedoch ebenfalls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Code Review: Betrachten Sie das Python-Modul V1A2_Classifier.py aus Aufgabe 2. Versuchen Sie die Implementierung der Methode Classifier.crossvalidate(self,S,X,T) zu verstehen:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Was bedeutet der Parameter S ?__\n",
    "\n",
    "S steht hier für die Anzahl der Teile, in welche die Testdaten geteilt werden, und dementsprechend auch für die Anzahl der Durchläufe von Training und Validierung -> S-Fache Kreuzvalidierung\n",
    "\n",
    "__Welche Rolle spielen die Variablen perm sowie Xp und Tp ?__\n",
    "\n",
    "__perm__: Bei einer Permutation handelt es sich um eine Umstellung der Reihnenfolge, in perm wird nun also eine zufällig generierte Zahlenfolge für Indexe der Länge X=T erstellt. \n",
    "\n",
    "__Xp__ und __Tp__: in Xp und Tp werden nun X und T mittels der Indexreihenfolge von perm permutiert und gespeichert.\n",
    "\n",
    "__Welche Rolle spielt idxS ?__\n",
    "In idxS werden Start und Endpunkte der S Aufteilungen der Testdaten gespeichert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[range(0, 4), range(4, 8), range(8, 12), range(12, 16)]\n"
     ]
    }
   ],
   "source": [
    "#Bsp idxS\n",
    "N=16\n",
    "S=4\n",
    "idxS = [range(i*N//S,(i+1)*N//S) for i in range(S)]\n",
    "print(idxS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Was bewirkt die äußere Schleife for idxTest in idxS: ... ?__\n",
    "in diesem Loop wird über alle zuvor generierten Datensets [range(x, y)] iteriert ->bsp: __if i not in idxTest__ \n",
    "\n",
    "__Welche Rolle haben die Variablen X_learn und T_learn bzw. X_test und T_test ?__\n",
    "X_learn und T_learn stehen für die Lerndatensets mit welchen der Klassifier in diesem Durchgang trainiert wird , X_test und T_test stehen für die Test bzw validierungsdaten des Durchgangs.\n",
    "\n",
    "__Was passiert für S=1 ?__\n",
    "für S=1 wird das gesamte Datenset sowohl zum Lernen als auch zum Testen verwendet. Dies sollte vermieden werden!\n",
    "\n",
    "__Was bewirkt die innere Schleife for i in range(len(X_test)): ... ?__\n",
    "In dieser Schleife wird über alle in X_test gespeicherten Testvektoren des Testdatensets des Durchganges iteriert.\n",
    "\n",
    "__Was bedeuten die Ergebnisse der Kreuzvalidierung pClassError und pConfErrors?__\n",
    "\n",
    "__pClassError:__ gibt die Wahrscheinlichkeit einer Falschklassifizierung zurück, diese wird aus 1-Accuracy berechnet.\n",
    "\n",
    "__pConfErrors:__ gibt eine Konfusionsmatrix pConfErrors[i,j] zurück. Diese gibt die Wahrscheinlichkeit an, dass ein Vektor der Klasse j als Klasse i Falschklassifiziert wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Wir betrachten nun ein 2-Klassen-Problem für Gauß-verteilte Datenvektoren__\n",
    "\n",
    "__Versuchen Sie das Programmgerüst V1A3_CrossVal_KNN.py zu verstehen und zu vervollständigen:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Wozu benötigt man den Befehl from V1A2_Classifier import * ?__\n",
    "dieser Befehl wird benötigt um auf das in Aufgabe 2 erstellte Modul mit den k-NN-Klassifikationen zugreifen zu können.\n",
    "\n",
    "__Mit welchem Befehl werden die Gauß-verteilten Datenvektoren erzeugt? Wieviele Datenpunkte werden generiert? Was bedeuten die Variablen N, N1, N2?__\n",
    "\n",
    "X1 = np.random.multivariate_normal(mu1,sigma1,(N1)) zur Erzeugung der Gauß-Verteilten Datenvektoren.\n",
    "\n",
    "Es werden N1+N2 = 1000 Datenpunkte generiert.\n",
    "N, N1 und N2 stehen für die Anzahl der Datenpunkte.\n",
    "\n",
    "__Welche Klassenspezifischen Verteilungen haben die Daten? Geben Sie für jede Klasse Mittelwert und Kovarianzmatrix an__\n",
    "\n",
    "mu1, mu2 = [1,1], [3,1]           # expectations for the two classes\n",
    "\n",
    "sigma1 = [[1,0.5],\\\n",
    "          [0.5,1]]                # covariance matrix for class 1\n",
    "\n",
    "sigma2 = [[1,0.5],\\\n",
    "          [0.5,1]]                # covariance matrix for class 2\n",
    "          \n",
    "__Welche Bedeutung haben die Variablen pE_naive, pCE_naive und t_naive ?__\n",
    "\n",
    "pE_naive und pCE_naive enthalten die  Rückgabewerte der Kreuzvalidation mittels eines naiven k-NN, also die pClassError und pConfError sowie mit t_naive die benötigte Zeit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: N= 1000 , D= 2\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S= 10  fold Cross-Validation of naive  5 -NN-Classifier requires  23.135540477000177  seconds. Confusion error probability matrix is \n",
      " [[0.862 0.172]\n",
      " [0.138 0.828]]\n",
      "Probability of a classification error is pE =  0.155\n",
      "New data vector x_test= [2 1]  is most likely from class  1 ; class probabilities are p_class =  [0.6, 0.4]\n",
      "New data vector x_test= [5 1]  is most likely from class  1 ; class probabilities are p_class =  [1.0]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0 ; class probabilities are p_class =  [1.0]\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 10  fold Cross-Validation of kdTree  5 -NN-Classifier requires  0.2739618949999567  seconds. Confusion error probability matrix is \n",
      " [[0.862 0.168]\n",
      " [0.138 0.832]]\n",
      "Probability of a classification error is pE =  0.153\n",
      "New data vector x_test= [2 1]  is most likely from class  1 ; class probabilities are p_class =  [0.6, 0.4]\n",
      "New data vector x_test= [5 1]  is most likely from class  1 ; class probabilities are p_class =  [1.0]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0 ; class probabilities are p_class =  [1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# Programmgeruest zu Versuch 1, Aufgabe 3\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from random import randint\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "from time import clock\n",
    "from V1A2_Classifier import *\n",
    "\n",
    "# (i) create some synthetic data (2-dimensional Gaussian)\n",
    "C=2                               # two classes\n",
    "N1,N2=500,500                     # N1 and N2 data vectors for the two classes\n",
    "mu1, mu2 = [1,1], [3,1]           # expectations for the two classes\n",
    "sigma1 = [[1,0.5],\\\n",
    "          [0.5,1]]                # covariance matrix for class 1\n",
    "sigma2 = [[1,0.5],\\\n",
    "          [0.5,1]]                # covariance matrix for class 2\n",
    "X1 = np.random.multivariate_normal(mu1,sigma1,(N1))    # Gaussian data vectors for class 1\n",
    "X2 = np.random.multivariate_normal(mu2,sigma2,(N2))    # Gaussian data vectors for class 2\n",
    "T1,T2 = N1*[0],N2*[1]             # corresponding class labels \n",
    "X = np.concatenate((X1,X2))       # entire data set\n",
    "T = np.concatenate((T1,T2))       # entire label set\n",
    "N,D = X.shape[0], X.shape[1]      # size of data set\n",
    "print (\"Data size: N=\",N,\", D=\",D)\n",
    "\n",
    "# (ii) create and test classifiers\n",
    "k,S = 5,10                        # k=number of nearest neighbors; S=number of data subsets for cross validation\n",
    "X_test = np.array([[2,1],[5,1],[-1,1]])   # Some additional data vectors to be tested \n",
    "\n",
    "# (ii.a) test of naive KNN classifier\n",
    "print (\"\\nNaive KNN Classifier:\",\"\\n------------------------\")\n",
    "knnc = KNNClassifier(C,k)         # create classifier object of class KNNClassifier\n",
    "t1=clock()                        # start time     \n",
    "pE_naive,pCE_naive = knnc.crossvalidate(S,X,T) # do S-fold cross validation for data X,T\n",
    "t2=clock()                        # end time\n",
    "t_naive=t2-t1                     # wall time required by the naive KNN algorithmus (in seconds)\n",
    "print (\"S=\", S, \" fold Cross-Validation of naive \", k, \"-NN-Classifier requires \", t_naive, \" seconds. Confusion error probability matrix is \\n\", pCE_naive)\n",
    "print (\"Probability of a classification error is pE = \", pE_naive)\n",
    "knnc.fit(X,T)                     # train classifier with whole data set\n",
    "for x_test in X_test:             # Test some additional data vectors x_test from X_test         \n",
    "    t_test,p_class,idxNN = knnc.predict(x_test,k)\n",
    "    print (\"New data vector x_test=\", x_test, \" is most likely from class \", t_test, \"; class probabilities are p_class = \", p_class)\n",
    "\n",
    "# (ii.b) test of KD-tree KNN classifier\n",
    "print (\"\\nFast KNN Classifier based on KD-Trees:\",\"\\n---------------------------------------\")\n",
    "fknnc = FastKNNClassifier(C,k)\n",
    "ft1=clock()\n",
    "pE_kdtree,pCE_kdtree=fknnc.crossvalidate(S,X,T)  \n",
    "ft2=clock()                        # end time\n",
    "t_kdtree=ft2-ft1 \n",
    "\n",
    "print (\"S=\", S, \" fold Cross-Validation of kdTree \", k, \"-NN-Classifier requires \", t_kdtree, \" seconds. Confusion error probability matrix is \\n\", pCE_kdtree)\n",
    "print (\"Probability of a classification error is pE = \", pE_kdtree)\n",
    "fknnc.fit(X,T)                     # train classifier with whole data set\n",
    "for x_test in X_test:             # Test some additional data vectors x_test from X_test         \n",
    "    t_test,p_class,idxNN = fknnc.predict(x_test,k)\n",
    "    print (\"New data vector x_test=\", x_test, \" is most likely from class \", t_test, \"; class probabilities are p_class = \", p_class)# REPLACE BY YOUR OWN CODE\n",
    "\n",
    "# (iii) plot data\n",
    "f=plt.figure()\n",
    "a = f.add_subplot(111)\n",
    "a.plot(X1.T[0],X1.T[1],'rx')               # plot data vectors of class 1\n",
    "a.plot(X2.T[0],X2.T[1],'g+')               # plot data vectors of class 2\n",
    "a.set_xlabel('feature x1');\n",
    "a.set_ylabel('feature x2');\n",
    "a.set_title('Naive: '+str(t_naive)+'sec/ KD-Tree: '+str(t_kdtree)+'sec; Classification Error='+str(pE_naive)+'/'+str(pE_kdtree));\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bestimmen Sie Klassifikationsfehler und Verwechslungswahrscheinlichkeiten für die gegebenen Daten bei Kreuzvalidierung mit dem k-NN-Klassifikator für k = 1, k= 5, k= 11 kombiniert mit S = 1, S = 2, S= 5?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: N= 1000 , D= 2\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S= 1  fold Cross-Validation of naive  1 -NN-Classifier requires  5.100293343999965  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "Probability of a classification error is pE =  0.0\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 1  fold Cross-Validation of kdTree  1 -NN-Classifier requires  0.12679501299999174  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "Probability of a classification error is pE =  0.0\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "S= 2  fold Cross-Validation of naive  1 -NN-Classifier requires  2.5949141779997262  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.828 0.184]\n",
      " [0.172 0.816]]\n",
      "\n",
      "Probability of a classification error is pE =  0.178\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 2  fold Cross-Validation of kdTree  1 -NN-Classifier requires  0.1363311770001019  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.84 0.16]\n",
      " [0.16 0.84]]\n",
      "\n",
      "Probability of a classification error is pE =  0.16\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "S= 5  fold Cross-Validation of naive  1 -NN-Classifier requires  3.9660346460000255  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.818 0.158]\n",
      " [0.182 0.842]]\n",
      "\n",
      "Probability of a classification error is pE =  0.17\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 5  fold Cross-Validation of kdTree  1 -NN-Classifier requires  0.1706210209999881  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.828 0.154]\n",
      " [0.172 0.846]]\n",
      "\n",
      "Probability of a classification error is pE =  0.163\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "S= 1  fold Cross-Validation of naive  5 -NN-Classifier requires  25.104531464000047  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.908 0.106]\n",
      " [0.092 0.894]]\n",
      "\n",
      "Probability of a classification error is pE =  0.099\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 1  fold Cross-Validation of kdTree  5 -NN-Classifier requires  0.20899029299971517  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.908 0.106]\n",
      " [0.092 0.894]]\n",
      "\n",
      "Probability of a classification error is pE =  0.099\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "S= 2  fold Cross-Validation of naive  5 -NN-Classifier requires  12.713658500999827  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.874 0.13 ]\n",
      " [0.126 0.87 ]]\n",
      "\n",
      "Probability of a classification error is pE =  0.128\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 2  fold Cross-Validation of kdTree  5 -NN-Classifier requires  0.23678597700018145  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.852 0.144]\n",
      " [0.148 0.856]]\n",
      "\n",
      "Probability of a classification error is pE =  0.146\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "S= 5  fold Cross-Validation of naive  5 -NN-Classifier requires  20.131067477000215  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.86  0.134]\n",
      " [0.14  0.866]]\n",
      "\n",
      "Probability of a classification error is pE =  0.137\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 5  fold Cross-Validation of kdTree  5 -NN-Classifier requires  0.22037392299989733  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.878 0.134]\n",
      " [0.122 0.866]]\n",
      "\n",
      "Probability of a classification error is pE =  0.128\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "S= 1  fold Cross-Validation of naive  11 -NN-Classifier requires  56.49004677499988  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.894 0.112]\n",
      " [0.106 0.888]]\n",
      "\n",
      "Probability of a classification error is pE =  0.109\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 1  fold Cross-Validation of kdTree  11 -NN-Classifier requires  0.3107639790000576  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.894 0.112]\n",
      " [0.106 0.888]]\n",
      "\n",
      "Probability of a classification error is pE =  0.109\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "S= 2  fold Cross-Validation of naive  11 -NN-Classifier requires  28.802061345999846  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.88 0.13]\n",
      " [0.12 0.87]]\n",
      "\n",
      "Probability of a classification error is pE =  0.125\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 2  fold Cross-Validation of kdTree  11 -NN-Classifier requires  0.3373165709999739  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.898 0.146]\n",
      " [0.102 0.854]]\n",
      "\n",
      "Probability of a classification error is pE =  0.124\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "S= 5  fold Cross-Validation of naive  11 -NN-Classifier requires  43.898187233000044  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.882 0.142]\n",
      " [0.118 0.858]]\n",
      "\n",
      "Probability of a classification error is pE =  0.13\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "S= 5  fold Cross-Validation of kdTree  11 -NN-Classifier requires  0.2565862369997376  seconds. \n",
      "Confusion error probability matrix is \n",
      " [[0.866 0.14 ]\n",
      " [0.134 0.86 ]]\n",
      "\n",
      "Probability of a classification error is pE =  0.137\n",
      "\n",
      "Naive KNN Classifier Table : \n",
      "---------------------------------------\n",
      " k   S         time          pCE [2,2]      pE \n",
      "--- --- ------------------ -------------- -----\n",
      "  1   1  5.100293343999965     1.0 .. 1.0   0.0\n",
      "  1   2 2.5949141779997262 0.828 .. 0.816 0.178\n",
      "  1   5 3.9660346460000255 0.818 .. 0.842  0.17\n",
      "  5   1 25.104531464000047 0.908 .. 0.894 0.099\n",
      "  5   2 12.713658500999827  0.874 .. 0.87 0.128\n",
      "  5   5 20.131067477000215  0.86 .. 0.866 0.137\n",
      " 11   1  56.49004677499988 0.894 .. 0.888 0.109\n",
      " 11   2 28.802061345999846   0.88 .. 0.87 0.125\n",
      " 11   5 43.898187233000044 0.882 .. 0.858  0.13\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees Table: \n",
      "---------------------------------------\n",
      " k   S          time          pCE [2,2]      pE \n",
      "--- --- ------------------- -------------- -----\n",
      "  1   1 0.12679501299999174     1.0 .. 1.0   0.0\n",
      "  1   2  0.1363311770001019   0.84 .. 0.84  0.16\n",
      "  1   5  0.1706210209999881 0.828 .. 0.846 0.163\n",
      "  5   1 0.20899029299971517 0.908 .. 0.894 0.099\n",
      "  5   2 0.23678597700018145 0.852 .. 0.856 0.146\n",
      "  5   5 0.22037392299989733 0.878 .. 0.866 0.128\n",
      " 11   1  0.3107639790000576 0.894 .. 0.888 0.109\n",
      " 11   2  0.3373165709999739 0.898 .. 0.854 0.124\n",
      " 11   5  0.2565862369997376  0.866 .. 0.86 0.137\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# Programmgeruest zu Versuch 1, Aufgabe 3\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from random import randint\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "from time import clock\n",
    "from astropy.table import Table\n",
    "from V1A2_Classifier import *\n",
    "\n",
    "# (i) create some synthetic data (2-dimensional Gaussian)\n",
    "C=2                               # two classes\n",
    "N1,N2=500,500                     # N1 and N2 data vectors for the two classes\n",
    "mu1, mu2 = [1,1], [3,1]           # expectations for the two classes\n",
    "sigma1 = [[1,0.5],\\\n",
    "          [0.5,1]]                # covariance matrix for class 1\n",
    "sigma2 = [[1,0.5],\\\n",
    "          [0.5,1]]                # covariance matrix for class 2\n",
    "X1 = np.random.multivariate_normal(mu1,sigma1,(N1))    # Gaussian data vectors for class 1\n",
    "X2 = np.random.multivariate_normal(mu2,sigma2,(N2))    # Gaussian data vectors for class 2\n",
    "T1,T2 = N1*[0],N2*[1]             # corresponding class labels \n",
    "X = np.concatenate((X1,X2))       # entire data set\n",
    "T = np.concatenate((T1,T2))       # entire label set\n",
    "N,D = X.shape[0], X.shape[1]      # size of data set\n",
    "\n",
    "#for saving Data for Tableview\n",
    "k_table, naive_k_table =[],[]\n",
    "S_table, naive_S_table =[],[]\n",
    "t_table, naive_t_table =[],[]\n",
    "pCE_table, naive_pCE_table =[], []\n",
    "pE_table, naive_pE_table =[],[]\n",
    "\n",
    "print (\"Data size: N=\",N,\", D=\",D)\n",
    "\n",
    "# (ii) create and test classifiers\n",
    "k_array = [1,5,11]   # k=number of nearest neighbors;\n",
    "S_array = [1,2,5]     #S=number of data subsets for cross validation\n",
    "X_test = np.array([[2,1],[5,1],[-1,1]])   # Some additional data vectors to be tested \n",
    "\n",
    "for k in k_array:\n",
    "    for S in S_array:\n",
    "        \n",
    "        # (ii.a) test of naive KNN classifier\n",
    "        print (\"\\nNaive KNN Classifier:\",\"\\n------------------------\")\n",
    "        knnc = KNNClassifier(C,k)         # create classifier object of class KNNClassifier\n",
    "        t1=clock()                        # start time     \n",
    "        pE_naive,pCE_naive = knnc.crossvalidate(S,X,T) # do S-fold cross validation for data X,T\n",
    "        t2=clock()                        # end time\n",
    "        t_naive=t2-t1                     # wall time required by the naive KNN algorithmus (in seconds)\n",
    "        \n",
    "        #save Data for Table view\n",
    "        naive_k_table.append(k)\n",
    "        naive_S_table.append(S)\n",
    "        naive_t_table.append(t_naive)\n",
    "        naive_pCE_table.append(pCE_naive)\n",
    "        naive_pE_table.append(pE_naive)\n",
    "        \n",
    "        print (\"S=\", S, \" fold Cross-Validation of naive \", k, \"-NN-Classifier requires \", t_naive, \" seconds. \\nConfusion error probability matrix is \\n\", pCE_naive)\n",
    "        print (\"\\nProbability of a classification error is pE = \", pE_naive)\n",
    "        \n",
    "        # (ii.b) test of KD-tree KNN classifier\n",
    "        print (\"\\nFast KNN Classifier based on KD-Trees:\",\"\\n---------------------------------------\")\n",
    "        fknnc = FastKNNClassifier(C,k)\n",
    "        ft1=clock()\n",
    "        pE_kdtree,pCE_kdtree=fknnc.crossvalidate(S,X,T)  \n",
    "        ft2=clock()                        # end time\n",
    "        t_kdtree=ft2-ft1 \n",
    "        \n",
    "        #save Data for Table view\n",
    "        k_table.append(k)\n",
    "        S_table.append(S)\n",
    "        t_table.append(t_kdtree)\n",
    "        pCE_table.append(pCE_kdtree)\n",
    "        pE_table.append(pE_kdtree)\n",
    "\n",
    "        print (\"S=\", S, \" fold Cross-Validation of kdTree \", k, \"-NN-Classifier requires \", t_kdtree, \" seconds. \\nConfusion error probability matrix is \\n\", pCE_kdtree)\n",
    "        print (\"\\nProbability of a classification error is pE = \", pE_kdtree)\n",
    "        \n",
    "print (\"\\nNaive KNN Classifier Table :\",\"\\n---------------------------------------\")\n",
    "print(Table([naive_k_table, naive_S_table, naive_t_table, naive_pCE_table, naive_pE_table], names=('k', 'S', 'time', 'pCE', 'pE'))) \n",
    "            \n",
    "print (\"\\nFast KNN Classifier based on KD-Trees Table:\",\"\\n---------------------------------------\")\n",
    "print(Table([k_table, S_table, t_table, pCE_table, pE_table], names=('k', 'S', 'time', 'pCE', 'pE')))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sind die Ergebnisse für den KNNClassifier und den FastKNNClassifier gleich?\n",
    "Stellen Sie die Ergebnisse für einen der beiden Klassifikatoren jeweils in einer Tabelle dar.__\n",
    "\n",
    "Die Klassifizierung ist bei beiden gleich, sie unterscheiden sich jedoch in der Zeit, der Konfusionsmatrix und der Fehlerwarhscheinlichkeit. Hier ist der FastKNNClassifier in allen dreien deutlich besser (siehe Tabellen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bestimmen Sie die Klassenverteilungen für drei weitere Testpunkte (2,1), (5,1), (−1,1) für k = 1, k = 5, k= 11, \n",
    "k= 111, k= 511. Was ist jeweils die wahrscheinlichste Klasse?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: N= 1000 , D= 2\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  0\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  0\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  0\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  0\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  0\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  0\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  1\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  1\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Naive KNN Classifier: \n",
      "------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  1\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "New data vector x_test= [2 1]  is most likely from class  1\n",
      "class density for class 0: [[0.84134475 0.5       ]\n",
      " [0.97724987 0.5       ]]\n",
      "class density for class 1: [[0.15865525 0.5       ]\n",
      " [0.02275013 0.5       ]]\n",
      "New data vector x_test= [5 1]  is most likely from class  1\n",
      "class density for class 0: [[0.99996833 0.5       ]\n",
      " [1.         0.5       ]]\n",
      "class density for class 1: [[0.97724987 0.5       ]\n",
      " [0.99996833 0.5       ]]\n",
      "New data vector x_test= [-1  1]  is most likely from class  0\n",
      "class density for class 0: [[2.27501319e-02 5.00000000e-01]\n",
      " [3.16712418e-05 5.00000000e-01]]\n",
      "class density for class 1: [[3.16712418e-05 5.00000000e-01]\n",
      " [6.22096057e-16 5.00000000e-01]]\n",
      "\n",
      "Naive KNN Classifier Table : \n",
      "---------------------------------------\n",
      " x [2]  class          cdf0 [2,2]                   cdf1 [2]          \n",
      "------- ----- --------------------------- ----------------------------\n",
      " 2 .. 1     0   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      " 2 .. 1     0   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      " 2 .. 1     0   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      " 2 .. 1     1   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      " 2 .. 1     1   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees Table: \n",
      "---------------------------------------\n",
      " x [2]  class          cdf0 [2,2]                  cdf1 [2,2]         \n",
      "------- ----- --------------------------- ----------------------------\n",
      " 2 .. 1     0   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      " 2 .. 1     0   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      " 2 .. 1     0   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      " 2 .. 1     1   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n",
      " 2 .. 1     1   0.8413447460685429 .. 0.5   0.15865525393145707 .. 0.5\n",
      " 5 .. 1     1   0.9999683287581669 .. 0.5    0.9772498680518208 .. 0.5\n",
      "-1 .. 1     0 0.022750131948179195 .. 0.5 3.167124183311986e-05 .. 0.5\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# Programmgeruest zu Versuch 1, Aufgabe 3\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from scipy.stats import norm\n",
    "from random import randint\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "from time import clock\n",
    "from astropy.table import Table\n",
    "from V1A2_Classifier import *\n",
    "\n",
    "# (i) create some synthetic data (2-dimensional Gaussian)\n",
    "C=2                               # two classes\n",
    "N1,N2=500,500                     # N1 and N2 data vectors for the two classes\n",
    "mu1, mu2 = [1,1], [3,1]           # expectations for the two classes\n",
    "sigma1 = [[1,0.5],\\\n",
    "          [0.5,1]]                # covariance matrix for class 1\n",
    "sigma2 = [[1,0.5],\\\n",
    "          [0.5,1]]                # covariance matrix for class 2\n",
    "X1 = np.random.multivariate_normal(mu1,sigma1,(N1))    # Gaussian data vectors for class 1\n",
    "X2 = np.random.multivariate_normal(mu2,sigma2,(N2))    # Gaussian data vectors for class 2\n",
    "T1,T2 = N1*[0],N2*[1]             # corresponding class labels \n",
    "X = np.concatenate((X1,X2))       # entire data set\n",
    "T = np.concatenate((T1,T2))       # entire label set\n",
    "N,D = X.shape[0], X.shape[1]      # size of data set\n",
    "print (\"Data size: N=\",N,\", D=\",D)\n",
    "\n",
    "# (ii) create and test classifiers\n",
    "k_array = [1,5,11,111,511]   # k=number of nearest neighbors;\n",
    "S = 10     #S=number of data subsets for cross validation\n",
    "X_test = np.array([[2,1],[5,1],[-1,1]])   # Some additional data vectors to be tested \n",
    "\n",
    "#for saving data for table\n",
    "x_naive_table, x_fast_table = [],[]\n",
    "t_test_naive_table, t_test_fast_table=[],[]\n",
    "cdf0_naive_table, cdf0_fast_table = [],[]\n",
    "cdf1_naive_table, cdf1_fast_table=[],[]\n",
    "for k in k_array:\n",
    "    \n",
    "        \n",
    "        # (ii.a) test of naive KNN classifier\n",
    "        print (\"\\nNaive KNN Classifier:\",\"\\n------------------------\")\n",
    "        knnc = KNNClassifier(C,k)         # create classifier object of class KNNClassifier\n",
    "        knnc.fit(X,T)                     # train classifier with whole data set\n",
    "        for x_test in X_test:             # Test some additional data vectors x_test from X_test         \n",
    "            t_test,p_class,idxNN = knnc.predict(x_test,k)\n",
    "            cdf0_naive=norm.cdf(x_test, mu1, sigma1)\n",
    "            cdf1_naive=norm.cdf(x_test, mu2, sigma2)\n",
    "            \n",
    "            x_naive_table.append(x_test)\n",
    "            t_test_naive_table.append(t_test)\n",
    "            cdf0_naive_table.append(cdf0_naive)\n",
    "            cdf1_naive_table.append(cdf1_naive[0])\n",
    "            \n",
    "            print (\"New data vector x_test=\", x_test, \" is most likely from class \", t_test)\n",
    "            print (\"class density for class 0:\", cdf0_naive)\n",
    "            print (\"class density for class 1:\", cdf1_naive)\n",
    "\n",
    "        # (ii.b) test of KD-tree KNN classifier\n",
    "        print (\"\\nFast KNN Classifier based on KD-Trees:\",\"\\n---------------------------------------\")\n",
    "        fknnc = FastKNNClassifier(C,k)\n",
    "        fknnc.fit(X,T)                     # train classifier with whole data set\n",
    "        for x_test in X_test:             # Test some additional data vectors x_test from X_test         \n",
    "            t_test,p_class,idxNN = fknnc.predict(x_test,k)\n",
    "            cdf0_fast=norm.cdf(x_test, mu1, sigma1)\n",
    "            cdf1_fast=norm.cdf(x_test, mu2, sigma2)\n",
    "            \n",
    "            x_fast_table.append(x_test)\n",
    "            t_test_fast_table.append(t_test)\n",
    "            cdf0_fast_table.append(cdf0_fast)\n",
    "            cdf1_fast_table.append(cdf1_fast)\n",
    "            \n",
    "            print (\"New data vector x_test=\", x_test, \" is most likely from class \", t_test)# REPLACE BY YOUR OWN CODE\n",
    "            print (\"class density for class 0:\", cdf0_fast)\n",
    "            print (\"class density for class 1:\", cdf1_fast)\n",
    "        \n",
    "print (\"\\nNaive KNN Classifier Table :\",\"\\n---------------------------------------\")\n",
    "print(Table([x_naive_table, t_test_naive_table, cdf0_naive_table, cdf1_naive_table], names=('x', 'class', 'cdf0', 'cdf1'))) \n",
    "            \n",
    "print (\"\\nFast KNN Classifier based on KD-Trees Table:\",\"\\n---------------------------------------\")\n",
    "print (Table([x_fast_table, t_test_fast_table, cdf0_fast_table, cdf1_fast_table], names=('x', 'class', 'cdf0', 'cdf1')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sind die Ergebnisse für den KNNClassifier und den FastKNNClassifier gleich?\n",
    "Stellen Sie die Ergebnisse für einen der beiden Klassifikatoren jeweils in einer Tabelle dar.__\n",
    "Hier sind die Werte bei den beiden Klassifikatoren gleich (siehe Ausgabe oben)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Vergleichen Sie systematisch die Effizienz der beiden k-NN-Klassifikatoren mit k= 5, indem Sie die Laufzeiten von Kreuzvalidierungen mit S= 1 und S= 5 für eine zunehmende \n",
    "Anzahl N:=N1 + N2 ∈ {10,20,50,100,200,500,1000,2000,5000,10000}\n",
    "von Datenvektoren messen. Stellen Sie die gemessenen Laufzeiten als Funktion von N in einer Tabelle bzw. einem Schaubild dar__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 10\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.0\n",
      "Accuracy =  1.0\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "Computing time =  0.00635599499946693  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.0\n",
      "Accuracy =  1.0\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "Computing time =  0.0014053380000405014  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 20\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.0\n",
      "Accuracy =  1.0\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "Computing time =  0.023458874999960244  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.0\n",
      "Accuracy =  1.0\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "Computing time =  0.0029602880003949394  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 50\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.06\n",
      "Accuracy =  0.94\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.92 0.04]\n",
      " [0.08 0.96]]\n",
      "Computing time =  0.09458633099984581  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.06\n",
      "Accuracy =  0.94\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.92 0.04]\n",
      " [0.08 0.96]]\n",
      "Computing time =  0.007568691000415129  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 100\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.09\n",
      "Accuracy =  0.91\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.96 0.14]\n",
      " [0.04 0.86]]\n",
      "Computing time =  0.31887783000001946  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.09\n",
      "Accuracy =  0.91\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.96 0.14]\n",
      " [0.04 0.86]]\n",
      "Computing time =  0.016415212000538304  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 200\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.11\n",
      "Accuracy =  0.89\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.87 0.09]\n",
      " [0.13 0.91]]\n",
      "Computing time =  1.0809533709998504  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.11\n",
      "Accuracy =  0.89\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.87 0.09]\n",
      " [0.13 0.91]]\n",
      "Computing time =  0.04227224199985358  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 500\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.114\n",
      "Accuracy =  0.886\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.88  0.108]\n",
      " [0.12  0.892]]\n",
      "Computing time =  6.455064525000125  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.114\n",
      "Accuracy =  0.886\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.88  0.108]\n",
      " [0.12  0.892]]\n",
      "Computing time =  0.09068572999967728  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 1000\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.125\n",
      "Accuracy =  0.875\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.88 0.13]\n",
      " [0.12 0.87]]\n",
      "Computing time =  25.639489041999695  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.125\n",
      "Accuracy =  0.875\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.88 0.13]\n",
      " [0.12 0.87]]\n",
      "Computing time =  0.2080594540002494  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 2000\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.1205\n",
      "Accuracy =  0.8795\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.875 0.116]\n",
      " [0.125 0.884]]\n",
      "Computing time =  98.18903884000065  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.1205\n",
      "Accuracy =  0.8795\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.875 0.116]\n",
      " [0.125 0.884]]\n",
      "Computing time =  0.40131904400004714  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 5000\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.1064\n",
      "Accuracy =  0.8936\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.8992 0.112 ]\n",
      " [0.1008 0.888 ]]\n",
      "Computing time =  609.3169115420005  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.1064\n",
      "Accuracy =  0.8936\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.8992 0.112 ]\n",
      " [0.1008 0.888 ]]\n",
      "Computing time =  1.0028248870003154  sec\n",
      "\n",
      "running KNN cross validation for K= 5 S= 1 N= 10000\n",
      "\n",
      "Naive KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the naive KNNClassifier yields the following results:\n",
      "Classification error probability =  0.1095\n",
      "Accuracy =  0.8905\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.8888 0.1078]\n",
      " [0.1112 0.8922]]\n",
      "Computing time =  2518.272946184001  sec\n",
      "\n",
      "Fast KNN Classifier based on KD-Trees: \n",
      "---------------------------------------\n",
      "\n",
      "S= 1  fold cross validation using the KD-Tree-KNNClassifier yields the following results:\n",
      "Classification error probability =  0.1095\n",
      "Accuracy =  0.8905\n",
      "Confusion Error Probabilities p(class i|class j) = \n",
      " [[0.8888 0.1078]\n",
      " [0.1112 0.8922]]\n",
      "Computing time =  3.870913812999788  sec\n",
      "\n",
      "Results for N= [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000] \n",
      "time_comp_naive= [6.35599500e-03 2.34588750e-02 9.45863310e-02 3.18877830e-01\n",
      " 1.08095337e+00 6.45506453e+00 2.56394890e+01 9.81890388e+01\n",
      " 6.09316912e+02 2.51827295e+03] \n",
      "time_comp_kdtree= [1.40533800e-03 2.96028800e-03 7.56869100e-03 1.64152120e-02\n",
      " 4.22722420e-02 9.06857300e-02 2.08059454e-01 4.01319044e-01\n",
      " 1.00282489e+00 3.87091381e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Programmgeruest zu Versuch 1, Aufgabe 3e\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import clock\n",
    "from V1A2_Classifier import *\n",
    "\n",
    "# (i) define parameters K,S,N and 2-dimensional Gaussian\n",
    "C=2\n",
    "k=5\n",
    "S=1\n",
    "N_list=[10,20,50,100,200,500,1000,2000,5000,10000]                      #Insert list of data set size N as desired\n",
    "mu1, mu2 = [1,1], [3,1]               # expectations for the two classes\n",
    "cov1 = [[1,0.5],\\\n",
    "        [0.5,1]]                      # covariance matrix for class 1\n",
    "cov2 = [[1,0.5],\\\n",
    "        [0.5,1]]                      # covariance matrix for class 2\n",
    "time_comp_naive  = np.zeros(len(N_list));    # allocate memory for time measurements for naive KNN\n",
    "time_comp_kdtree = np.zeros(len(N_list));    # allocate memory for time measurements for KNN with KD tree\n",
    "\n",
    "# (ii) Make (wall-)time measurements for cross validations of data sets of various sizes N\n",
    "for i in range(len(N_list)):\n",
    "    N=N_list[i]\n",
    "    print (\"\\nrunning KNN cross validation for K=\",K,\"S=\",S,\"N=\",N)\n",
    "\n",
    "    # (ii.a) generate synthetic data \n",
    "    N1,N2=int(N/2),int(N/2)                     # N1 and N2 data vectors for the two classes  \n",
    "    X1 = np.random.multivariate_normal(mu1,cov1,(N1))    # Gaussian data vectors for class 1\n",
    "    X2 = np.random.multivariate_normal(mu2,cov2,(N2))    # Gaussian data vectors for class 2\n",
    "    T1,T2 = N1*[0],N2*[1]             # corresponding class labels \n",
    "    X = np.concatenate((X1,X2))       # entire data set\n",
    "    T = np.concatenate((T1,T2))       # entire label set\n",
    "\n",
    "    # (ii.b) do cross validation for this data set using naive KNN\n",
    "    print (\"\\nNaive KNN Classifier based on KD-Trees:\",\"\\n---------------------------------------\")\n",
    "    knnc = KNNClassifier(C,K)         # create classifier object of class KNNClassifier\n",
    "    t1=clock()                        # start time\n",
    "    pE,pCE = knnc.crossvalidate(S,X,T)# do S-fold cross validation for data X,T\n",
    "    t2=clock()                        # end time\n",
    "    time_comp_naive[i]=t2-t1          # computing time in seconds\n",
    "    print (\"\\nS=\",S,\" fold cross validation using the naive KNNClassifier yields the following results:\")\n",
    "    print (\"Classification error probability = \", pE)\n",
    "    print (\"Accuracy = \", 1.0-pE)\n",
    "    print (\"Confusion Error Probabilities p(class i|class j) = \\n\", pCE)\n",
    "    print (\"Computing time = \", time_comp_naive[i], \" sec\") \n",
    "\n",
    "    # (ii.c) do cross validation for this data set using KNN with KD trees\n",
    "    print (\"\\nFast KNN Classifier based on KD-Trees:\",\"\\n---------------------------------------\")\n",
    "    fknnc = FastKNNClassifier(C,k)\n",
    "    ft1=clock()\n",
    "    pE_kdtree,pCE_kdtree=fknnc.crossvalidate(S,X,T)  \n",
    "    ft2=clock()                        # end time\n",
    "    time_comp_kdtree[i]=ft2-ft1 \n",
    "\n",
    "    print (\"\\nS=\",S,\" fold cross validation using the KD-Tree-KNNClassifier yields the following results:\")\n",
    "    print (\"Classification error probability = \", pE)\n",
    "    print (\"Accuracy = \", 1.0-pE)\n",
    "    print (\"Confusion Error Probabilities p(class i|class j) = \\n\", pCE)\n",
    "    print (\"Computing time = \", time_comp_kdtree[i], \" sec\") \n",
    "\n",
    "# (iii) print results\n",
    "print (\"\\nResults for N=\",N_list,\"\\ntime_comp_naive=\",time_comp_naive,\"\\ntime_comp_kdtree=\",time_comp_kdtree)\n",
    "\n",
    "# (iv) plot results\n",
    "f=plt.figure()\n",
    "a = f.add_subplot(111)\n",
    "a.plot(N_list,time_comp_naive,'bo-',N_list,time_comp_kdtree,'gd-')       # plot computing times \n",
    "a.set_xlabel('number of data vectors N');\n",
    "a.set_ylabel('computing time [sec]');\n",
    "a.set_title('Computing time for '+str(S)+'-fold cross validation for KNN with K='+str(K));\n",
    "a.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
