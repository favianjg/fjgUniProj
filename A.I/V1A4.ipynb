{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4a und 4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Erstellen Sie einen k-Nearest-Neighbor-Klassifikator für die Wald-Daten. Importieren Sie hierfür wieder das Modul V1A2_Classifier.py aus Aufgabe 2 und verwenden Sie eine geeignete Klasse für den Klassifikator.__\n",
    "\n",
    "und \n",
    "\n",
    "__Testen Sie den Klassifikator für  k= 3 durch Kreuzvalidierung mit S = 5. Geben Sie die Klassifikationsfehlerwahrscheinlichkeit und Verwechslungsmatrix an.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S= 5  fold cross validation using the 3 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "accuracy=\n",
      " [[0.88718929]]\n",
      "\n",
      "p_classerror=\n",
      " [[0.11281071]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# Programmgeruest zu Versuch 1, Aufgabe 4)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import clock\n",
    "from random import randint\n",
    "from V1A2_Classifier import *\n",
    "\n",
    "# (I) Load data \n",
    "forestdata  = pd.read_csv('./ForestTypes/ForestTypesData.csv'); # load data as pandas data frame \n",
    "classlabels = ['s','h','d','o'];                                      # possible class labels (C=4) \n",
    "classidx    = {classlabels[i]:i for i in range(len(classlabels))}     # dict for mapping classlabel to index \n",
    "C           = len(classlabels)        # number of classes (Note: K is now the number of nearest-neighbors!!!!!!)\n",
    "T_txt = forestdata.values[:,0]        # array of class labels of data vectors (class label is first data attribute)\n",
    "X = forestdata.values[:,1:]           # array of feature vectors (features are remaining attributes)\n",
    "T = [classidx[t.strip()] for t in T_txt]          # transform text labels 's','h','d','o' to numeric lables 0,1,2,3\n",
    "N,D=X.shape                           # size and dimensionality of data set\n",
    "#print (\"Data set 'ForestData' has size N=\", N, \" and dimensionality D=\",D, \" and C=\", C, \" different classes\")\n",
    "#print (\"X[0..9]=\\n\",X[0:10])\n",
    "#print (\"T_txt[0..9]=\\n\",T_txt[0:10])\n",
    "#print (\"T[0..9]=\\n\",T[0:10])\n",
    "\n",
    "# (II) Test KNN-classifier with S-fold cross validation\n",
    "S_list=[5]                            # parameter S for cross validation; INSERT appropriate values\n",
    "K_list=[3]                            # number K of nearest neighbors; INSERT appropriate values\n",
    "accuracy = np.zeros((len(S_list),len(K_list)));   # array to save accuracy of classifier for each value of S and K\n",
    "for i in range(len(S_list)):\n",
    "    S=S_list[i]                      # do an S-fold cross validation\n",
    "    for j in range(len(K_list)):\n",
    "        k=K_list[j]\n",
    "        t1=clock()                   # start time\n",
    "        fknnc = FastKNNClassifier(C,k)       #  create appropriate KNN classifier (with kd-trees) \n",
    "        pE,pCE = fknnc.crossvalidate(S,X,T) #  Do S-fold cross validation and get error probabilities / confusion matrix\n",
    "        t2=clock()                            # end time\n",
    "        time_comp=t2-t1                       # computing time in seconds\n",
    "        print (\"\\nS=\",S,\" fold cross validation using the\",k,\"-NNClassifier with KD-Trees yields the following results:\")\n",
    "        print (\"Classification error probability = \", pE)\n",
    "        print (\"Accuracy = \", 1.0-pE)\n",
    "        #print (\"Confusion Error Probabilities p(class i|class j) = \\n\", pCE)\n",
    "        #print (\"Computing time = \", time_comp, \" sec\") \n",
    "        accuracy[i,j]=1.0-pE\n",
    "print (\"\\naccuracy=\\n\",accuracy)\n",
    "print (\"\\np_classerror=\\n\",1.0-accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Versuchen Sie die Klassifikationsleistung zu optimieren, z.B. in dem Sie k variieren. Für welches k ist der Klassifikationsfehler am kleinsten? Ändert sich Ihr Ergebnis für ver- schiedene S ∈{ 1,2,3,5,10,100}?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S= 1  fold cross validation using the 3 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.055449330783938815\n",
      "Accuracy =  0.9445506692160612\n",
      "\n",
      "S= 1  fold cross validation using the 4 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.0497131931166348\n",
      "Accuracy =  0.9502868068833652\n",
      "\n",
      "S= 1  fold cross validation using the 5 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.08221797323135756\n",
      "Accuracy =  0.9177820267686424\n",
      "\n",
      "S= 1  fold cross validation using the 6 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.07074569789674952\n",
      "Accuracy =  0.9292543021032504\n",
      "\n",
      "S= 1  fold cross validation using the 7 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.08604206500956023\n",
      "Accuracy =  0.9139579349904398\n",
      "\n",
      "S= 1  fold cross validation using the 8 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.08221797323135756\n",
      "Accuracy =  0.9177820267686424\n",
      "\n",
      "S= 1  fold cross validation using the 9 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.09177820267686425\n",
      "Accuracy =  0.9082217973231358\n",
      "\n",
      "S= 1  fold cross validation using the 10 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.08604206500956023\n",
      "Accuracy =  0.9139579349904398\n",
      "\n",
      "S= 1  fold cross validation using the 11 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.09369024856596558\n",
      "Accuracy =  0.9063097514340344\n",
      "\n",
      "S= 1  fold cross validation using the 12 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.08986615678776291\n",
      "Accuracy =  0.9101338432122371\n",
      "\n",
      "S= 2  fold cross validation using the 3 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11854684512428298\n",
      "Accuracy =  0.881453154875717\n",
      "\n",
      "S= 2  fold cross validation using the 4 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1147227533460803\n",
      "Accuracy =  0.8852772466539197\n",
      "\n",
      "S= 2  fold cross validation using the 5 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.124282982791587\n",
      "Accuracy =  0.875717017208413\n",
      "\n",
      "S= 2  fold cross validation using the 6 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "S= 2  fold cross validation using the 7 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11854684512428298\n",
      "Accuracy =  0.881453154875717\n",
      "\n",
      "S= 2  fold cross validation using the 8 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1147227533460803\n",
      "Accuracy =  0.8852772466539197\n",
      "\n",
      "S= 2  fold cross validation using the 9 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.13766730401529637\n",
      "Accuracy =  0.8623326959847036\n",
      "\n",
      "S= 2  fold cross validation using the 10 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.12045889101338432\n",
      "Accuracy =  0.8795411089866156\n",
      "\n",
      "S= 2  fold cross validation using the 11 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.12619502868068833\n",
      "Accuracy =  0.8738049713193117\n",
      "\n",
      "S= 2  fold cross validation using the 12 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.12619502868068833\n",
      "Accuracy =  0.8738049713193117\n",
      "\n",
      "S= 3  fold cross validation using the 3 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 3  fold cross validation using the 4 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 3  fold cross validation using the 5 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 3  fold cross validation using the 6 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10133843212237094\n",
      "Accuracy =  0.8986615678776291\n",
      "\n",
      "S= 3  fold cross validation using the 7 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.12810707456978968\n",
      "Accuracy =  0.8718929254302104\n",
      "\n",
      "S= 3  fold cross validation using the 8 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1089866156787763\n",
      "Accuracy =  0.8910133843212237\n",
      "\n",
      "S= 3  fold cross validation using the 9 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 3  fold cross validation using the 10 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1147227533460803\n",
      "Accuracy =  0.8852772466539197\n",
      "\n",
      "S= 3  fold cross validation using the 11 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.12619502868068833\n",
      "Accuracy =  0.8738049713193117\n",
      "\n",
      "S= 3  fold cross validation using the 12 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.12045889101338432\n",
      "Accuracy =  0.8795411089866156\n",
      "\n",
      "S= 5  fold cross validation using the 3 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.124282982791587\n",
      "Accuracy =  0.875717017208413\n",
      "\n",
      "S= 5  fold cross validation using the 4 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.0994263862332696\n",
      "Accuracy =  0.9005736137667304\n",
      "\n",
      "S= 5  fold cross validation using the 5 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "S= 5  fold cross validation using the 6 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10516252390057361\n",
      "Accuracy =  0.8948374760994264\n",
      "\n",
      "S= 5  fold cross validation using the 7 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 5  fold cross validation using the 8 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1089866156787763\n",
      "Accuracy =  0.8910133843212237\n",
      "\n",
      "S= 5  fold cross validation using the 9 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.124282982791587\n",
      "Accuracy =  0.875717017208413\n",
      "\n",
      "S= 5  fold cross validation using the 10 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10707456978967496\n",
      "Accuracy =  0.892925430210325\n",
      "\n",
      "S= 5  fold cross validation using the 11 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.12237093690248566\n",
      "Accuracy =  0.8776290630975143\n",
      "\n",
      "S= 5  fold cross validation using the 12 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 10  fold cross validation using the 3 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "S= 10  fold cross validation using the 4 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.0994263862332696\n",
      "Accuracy =  0.9005736137667304\n",
      "\n",
      "S= 10  fold cross validation using the 5 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "S= 10  fold cross validation using the 6 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10516252390057361\n",
      "Accuracy =  0.8948374760994264\n",
      "\n",
      "S= 10  fold cross validation using the 7 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10707456978967496\n",
      "Accuracy =  0.892925430210325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S= 10  fold cross validation using the 8 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 10  fold cross validation using the 9 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "S= 10  fold cross validation using the 10 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10133843212237094\n",
      "Accuracy =  0.8986615678776291\n",
      "\n",
      "S= 10  fold cross validation using the 11 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "S= 10  fold cross validation using the 12 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1147227533460803\n",
      "Accuracy =  0.8852772466539197\n",
      "\n",
      "S= 20  fold cross validation using the 3 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10516252390057361\n",
      "Accuracy =  0.8948374760994264\n",
      "\n",
      "S= 20  fold cross validation using the 4 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 20  fold cross validation using the 5 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10516252390057361\n",
      "Accuracy =  0.8948374760994264\n",
      "\n",
      "S= 20  fold cross validation using the 6 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10707456978967496\n",
      "Accuracy =  0.892925430210325\n",
      "\n",
      "S= 20  fold cross validation using the 7 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.0994263862332696\n",
      "Accuracy =  0.9005736137667304\n",
      "\n",
      "S= 20  fold cross validation using the 8 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.09369024856596558\n",
      "Accuracy =  0.9063097514340344\n",
      "\n",
      "S= 20  fold cross validation using the 9 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1089866156787763\n",
      "Accuracy =  0.8910133843212237\n",
      "\n",
      "S= 20  fold cross validation using the 10 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1089866156787763\n",
      "Accuracy =  0.8910133843212237\n",
      "\n",
      "S= 20  fold cross validation using the 11 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1147227533460803\n",
      "Accuracy =  0.8852772466539197\n",
      "\n",
      "S= 20  fold cross validation using the 12 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "S= 100  fold cross validation using the 3 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1089866156787763\n",
      "Accuracy =  0.8910133843212237\n",
      "\n",
      "S= 100  fold cross validation using the 4 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10325047801147227\n",
      "Accuracy =  0.8967495219885278\n",
      "\n",
      "S= 100  fold cross validation using the 5 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11089866156787763\n",
      "Accuracy =  0.8891013384321224\n",
      "\n",
      "S= 100  fold cross validation using the 6 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10325047801147227\n",
      "Accuracy =  0.8967495219885278\n",
      "\n",
      "S= 100  fold cross validation using the 7 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.10325047801147227\n",
      "Accuracy =  0.8967495219885278\n",
      "\n",
      "S= 100  fold cross validation using the 8 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.0994263862332696\n",
      "Accuracy =  0.9005736137667304\n",
      "\n",
      "S= 100  fold cross validation using the 9 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1089866156787763\n",
      "Accuracy =  0.8910133843212237\n",
      "\n",
      "S= 100  fold cross validation using the 10 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1089866156787763\n",
      "Accuracy =  0.8910133843212237\n",
      "\n",
      "S= 100  fold cross validation using the 11 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.11281070745697896\n",
      "Accuracy =  0.887189292543021\n",
      "\n",
      "S= 100  fold cross validation using the 12 -NNClassifier with KD-Trees yields the following results:\n",
      "Classification error probability =  0.1089866156787763\n",
      "Accuracy =  0.8910133843212237\n",
      "\n",
      "accuracy=\n",
      " [[0.94455067 0.95028681 0.91778203 0.9292543  0.91395793 0.91778203\n",
      "  0.9082218  0.91395793 0.90630975 0.91013384]\n",
      " [0.88145315 0.88527725 0.87571702 0.88718929 0.88145315 0.88527725\n",
      "  0.8623327  0.87954111 0.87380497 0.87380497]\n",
      " [0.88910134 0.88910134 0.88910134 0.89866157 0.87189293 0.89101338\n",
      "  0.88910134 0.88527725 0.87380497 0.87954111]\n",
      " [0.87571702 0.90057361 0.88718929 0.89483748 0.88910134 0.89101338\n",
      "  0.87571702 0.89292543 0.87762906 0.88910134]\n",
      " [0.88718929 0.90057361 0.88718929 0.89483748 0.89292543 0.88910134\n",
      "  0.88718929 0.89866157 0.88718929 0.88527725]\n",
      " [0.89483748 0.88910134 0.89483748 0.89292543 0.90057361 0.90630975\n",
      "  0.89101338 0.89101338 0.88527725 0.88718929]\n",
      " [0.89101338 0.89674952 0.88910134 0.89674952 0.89674952 0.90057361\n",
      "  0.89101338 0.89101338 0.88718929 0.89101338]]\n",
      "\n",
      "p_classerror=\n",
      " [[0.05544933 0.04971319 0.08221797 0.0707457  0.08604207 0.08221797\n",
      "  0.0917782  0.08604207 0.09369025 0.08986616]\n",
      " [0.11854685 0.11472275 0.12428298 0.11281071 0.11854685 0.11472275\n",
      "  0.1376673  0.12045889 0.12619503 0.12619503]\n",
      " [0.11089866 0.11089866 0.11089866 0.10133843 0.12810707 0.10898662\n",
      "  0.11089866 0.11472275 0.12619503 0.12045889]\n",
      " [0.12428298 0.09942639 0.11281071 0.10516252 0.11089866 0.10898662\n",
      "  0.12428298 0.10707457 0.12237094 0.11089866]\n",
      " [0.11281071 0.09942639 0.11281071 0.10516252 0.10707457 0.11089866\n",
      "  0.11281071 0.10133843 0.11281071 0.11472275]\n",
      " [0.10516252 0.11089866 0.10516252 0.10707457 0.09942639 0.09369025\n",
      "  0.10898662 0.10898662 0.11472275 0.11281071]\n",
      " [0.10898662 0.10325048 0.11089866 0.10325048 0.10325048 0.09942639\n",
      "  0.10898662 0.10898662 0.11281071 0.10898662]]\n"
     ]
    }
   ],
   "source": [
    "# Programmgeruest zu Versuch 1, Aufgabe 4)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import clock\n",
    "from random import randint\n",
    "from V1A2_Classifier import *\n",
    "\n",
    "# (I) Load data \n",
    "forestdata  = pd.read_csv('./ForestTypes/ForestTypesData.csv'); # load data as pandas data frame \n",
    "classlabels = ['s','h','d','o'];                                      # possible class labels (C=4) \n",
    "classidx    = {classlabels[i]:i for i in range(len(classlabels))}     # dict for mapping classlabel to index \n",
    "C           = len(classlabels)        # number of classes (Note: K is now the number of nearest-neighbors!!!!!!)\n",
    "T_txt = forestdata.values[:,0]        # array of class labels of data vectors (class label is first data attribute)\n",
    "X = forestdata.values[:,1:]           # array of feature vectors (features are remaining attributes)\n",
    "T = [classidx[t.strip()] for t in T_txt]          # transform text labels 's','h','d','o' to numeric lables 0,1,2,3\n",
    "N,D=X.shape                           # size and dimensionality of data set\n",
    "#print (\"Data set 'ForestData' has size N=\", N, \" and dimensionality D=\",D, \" and C=\", C, \" different classes\")\n",
    "#print (\"X[0..9]=\\n\",X[0:10])\n",
    "#print (\"T_txt[0..9]=\\n\",T_txt[0:10])\n",
    "#print (\"T[0..9]=\\n\",T[0:10])\n",
    "\n",
    "# (II) Test KNN-classifier with S-fold cross validation\n",
    "S_list=[1,2,3,5,10,20,100]                            # parameter S for cross validation; INSERT appropriate values\n",
    "K_list=[i for i in range(3,13)]                            # number K of nearest neighbors; INSERT appropriate values\n",
    "accuracy = np.zeros((len(S_list),len(K_list)));   # array to save accuracy of classifier for each value of S and K\n",
    "for i in range(len(S_list)):\n",
    "    S=S_list[i]                      # do an S-fold cross validation\n",
    "    for j in range(len(K_list)):\n",
    "        k=K_list[j]\n",
    "        t1=clock()                   # start time\n",
    "        fknnc = FastKNNClassifier(C,k)       #  create appropriate KNN classifier (with kd-trees) \n",
    "        pE,pCE = fknnc.crossvalidate(S,X,T) #  Do S-fold cross validation and get error probabilities / confusion matrix\n",
    "        t2=clock()                            # end time\n",
    "        time_comp=t2-t1                       # computing time in seconds\n",
    "        print (\"\\nS=\",S,\" fold cross validation using the\",k,\"-NNClassifier with KD-Trees yields the following results:\")\n",
    "        print (\"Classification error probability = \", pE)\n",
    "        print (\"Accuracy = \", 1.0-pE)\n",
    "        #print (\"Confusion Error Probabilities p(class i|class j) = \\n\", pCE)\n",
    "        #print (\"Computing time = \", time_comp, \" sec\") \n",
    "        accuracy[i,j]=1.0-pE\n",
    "print (\"\\naccuracy=\\n\",accuracy)\n",
    "print (\"\\np_classerror=\\n\",1.0-accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswertung der Ausgabe: \n",
    "\n",
    "bei kleinen Werten für N ist die Accuracy meistens bei k=4 am höchsten, es gibt bei mehreren Ausführungen hin und wieder einige Ausreißer, bei denen 5 oder 6 den besten Wert vorweisen, im Schnitt ist dies jedoch bei k=4 der Fall.\n",
    "\n",
    "Für große N verschiebt sich dies auf k=8. Auch hier gibt es hin und wieder Ausreißer zu k=4 oder 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Theoretische Zusatzfrage: Bis auf k gelten k -NN-Verfahren als parameterfrei, d.h. unabhängig von irgendwelchen Annahmen über die Datenverteilung. Ist diese Annahme wirklich gerechtfertigt?__\n",
    "\n",
    "Was ist z.B. falls sich der Wertebereich verschiedener Merkmalsdimensionen um\n",
    "mehrere Größenordnungen unterscheiden? Wie könnte man hier abhelfen? -> hier könnte man abhelfen, indem man den Datenvektor normalisiert bevor dieser weiter ausgewertet wird."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
