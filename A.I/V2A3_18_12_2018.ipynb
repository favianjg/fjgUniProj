{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) lmbda : is used for regularization, prevents overfitting\n",
    "   deg : degree of polynomial, determines until which degree the phi would be\n",
    "   flagSTD : flags used to determined if the data needs scaling or not\n",
    "   without rescaling then the data could be far off from each other reducing the accuracy of the prediction result\n",
    "   \n",
    "b) K : how many nearest neighbors\n",
    "   flagKLinReg : flags used to determine wether to do linear least squares or take the average of the KNN\n",
    "   \n",
    "   \n",
    "data accuracy is to be determined by comparing my result from the program with the result of airfoil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set  ../DATA/AirfoilSelfNoise/airfoil_self_noise.xls  has size N= 1502  and dimensionality D= 5\n",
      "X= [[1.00000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " ...\n",
      " [4.00000e+03 1.56000e+01 1.01600e-01 3.96000e+01 5.28487e-02]\n",
      " [5.00000e+03 1.56000e+01 1.01600e-01 3.96000e+01 5.28487e-02]\n",
      " [6.30000e+03 1.56000e+01 1.01600e-01 3.96000e+01 5.28487e-02]]\n",
      "T= [125.201 125.951 127.591 ... 106.604 106.224 104.204]\n",
      "x_test_1= [0, 0, 0, 0, 0]\n",
      "x_test_2= [0, 0, 0, 0, 0]\n",
      "number of basis functions M= 6\n",
      "\n",
      "#### Least Squares Regression with regularization lambda= 1  ####\n",
      "lsr.W_LSR= [ 1.31004588e+02 -1.23902426e-03 -6.06620941e-01 -3.35499467e+01\n",
      "  1.21621508e-01 -1.51100354e+01]\n",
      "III.1) Some predictions on the training data:\n",
      "Prediction for X[ 1187 ]= [1.25000e+03 1.74000e+01 2.54000e-02 3.96000e+01 1.72206e-02]  is y= None , whereas true value is T[ 1187 ]= 131.364\n",
      "Prediction for X[ 82 ]= [6.30000e+02 1.50000e+00 3.04800e-01 3.96000e+01 3.92107e-03]  is y= None , whereas true value is T[ 82 ]= 128.311\n",
      "Prediction for X[ 1308 ]= [1.250e+03 3.300e+00 1.016e-01 5.550e+01 2.211e-03]  is y= None , whereas true value is T[ 1308 ]= 132.769\n",
      "Prediction for X[ 496 ]= [1.00000e+04 0.00000e+00 1.52400e-01 3.96000e+01 1.93287e-03]  is y= None , whereas true value is T[ 496 ]= 115.413\n",
      "Prediction for X[ 88 ]= [2.50000e+03 1.50000e+00 3.04800e-01 3.96000e+01 3.92107e-03]  is y= None , whereas true value is T[ 88 ]= 120.981\n",
      "III.2) Some predicitions for new test vectors:\n",
      "Prediction for x_test_1 is y= None\n",
      "Prediction for x_test_2 is y= None\n",
      "III.3) S= 3 fold Cross Validation:\n",
      "absolute errors (E,sd,min,max)= (209.95227161197485, 59.56185193307294, 152.7995579149364, 500.14440430239756) \n",
      "relative errors (E,sd,min,max)= (1.696499132492575, 0.5520173762614089, 1.223420231318363, 4.837922270288233)\n",
      "\n",
      "#### KNN regression with flagKLinReg= 0  ####\n",
      "IV.1) Some predictions on the training data:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-104aa48ea6da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_perm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Prediction for X[\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"]=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" is y=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mknnr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflagKLinReg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\", whereas true value is T[\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"]=\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# REPLACE dummy code: compute prediction for X[n]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"IV.2) Some predicitions for new test vectors:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Prediction for x_test_1 is y=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknnr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflagKLinReg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# REPLACE dummy code: compute prediction for x_test_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HS Albstadt\\Semester 5\\IAS\\Praktikum\\PRAKTIKUMSVERZEICHNIS\\versuch2\\V2A2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, K, flagKLinReg)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflagKLinReg\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;31m# just take mean value of KNNs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mt_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midxNN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;31m# do a linear regression of the KNNs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HS Albstadt\\Semester 5\\IAS\\Praktikum\\PRAKTIKUMSVERZEICHNIS\\versuch2\\V2A2.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflagKLinReg\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;31m# just take mean value of KNNs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mt_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midxNN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;31m# do a linear regression of the KNNs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# V2A3_regression_airfoilnoise.py\n",
    "# Programmgeruest zu Versuch 2, Aufgabe 3\n",
    "# to log outputs start with: python V2A3_regression_airfoilnoise.py >V2A3_regression_airfoilnoise.log\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from V2A2_Regression import *\n",
    "from V2A2 import *\n",
    "\n",
    "# ***** MAIN PROGRAM ********\n",
    "# (I) Hyper-Parameters\n",
    "S=3;               # S-fold cross-validation\n",
    "lmbda=1;           # regularization parameter (lambda>0 avoids also singularities)\n",
    "K=1;               # K for K-Nearest Neighbors\n",
    "flagKLinReg = 0;   # if flag==1 and K>=D then do a linear regression of the KNNs to make prediction\n",
    "deg=1;             # degree of basis function polynomials \n",
    "flagSTD=0;         # if >0 then standardize data before training (i.e., scale X to mean value 0 and standard deviation 1)\n",
    "N_pred=5;          # number of predictions on the training set for testing\n",
    "x_test_1 = [0,0,0,0,0];   # REPLACE dummy code: define test vector 1\n",
    "x_test_2 = [0,0,0,0,0];   # REPLACE dummy code: define test vector 2\n",
    "\n",
    "# (II) Load data \n",
    "fname=('../DATA/AirfoilSelfNoise/airfoil_self_noise.xls')\n",
    "airfoil_data = pd.read_excel(fname,0); # load data as pandas data frame \n",
    "T = airfoil_data.values[:,5]           # target values = noise load (= column 5 of data table)\n",
    "X = airfoil_data.values[:,:5]          # feature vectors (= column 0-4 of data table)\n",
    "N,D=X.shape                            # size and dimensionality of data set\n",
    "idx_perm = np.random.permutation(N)    # get random permutation for selection of test vectors \n",
    "print (\"Data set \",fname,\" has size N=\", N, \" and dimensionality D=\",D)\n",
    "print (\"X=\",X)\n",
    "print (\"T=\",T)\n",
    "print (\"x_test_1=\",x_test_1)\n",
    "print (\"x_test_2=\",x_test_2)\n",
    "print (\"number of basis functions M=\", len(phi_polynomial(X[1],deg)))\n",
    "\n",
    "# (III) Do least-squares regression with regularization \n",
    "print (\"\\n#### Least Squares Regression with regularization lambda=\", lmbda, \" ####\")\n",
    "phi=lambda X: phi_polynomial(X,deg)\n",
    "lsr = LSRRegressifier(lmbda,phi)\n",
    "lsr.fit(X,T)  # REPLACE dummy code: Create and fit Least-Squares Regressifier using polynomial basis function of degree deg and flagSTD for standardization of data  \n",
    "print (\"lsr.W_LSR=\", lsr.W_LSR)   # REPLACE dummy code: print weight vector for least squares regression  \n",
    "print (\"III.1) Some predictions on the training data:\")\n",
    "for i in range(N_pred): \n",
    "    n=idx_perm[i]\n",
    "    print (\"Prediction for X[\",n,\"]=\",X[n],\" is y=\",lsr.predict(X[n],flagSTD),\", whereas true value is T[\",n,\"]=\",T[n])   # REPLACE dummy code: compute prediction for X[n]\n",
    "print (\"III.2) Some predicitions for new test vectors:\")\n",
    "print (\"Prediction for x_test_1 is y=\", lsr.predict(x_test_1,flagSTD))    # REPLACE dummy code: compute prediction for x_test_1\n",
    "print (\"Prediction for x_test_2 is y=\", lsr.predict(x_test_2,flagSTD))    # REPLACE dummy code: compute prediction for x_test_2\n",
    "print (\"III.3) S=\",S,\"fold Cross Validation:\")\n",
    "err_abs,err_rel = lsr.crossvalidate(S,X,T)# REPLACE dummy code: do cross validation!! \n",
    "print (\"absolute errors (E,sd,min,max)=\", err_abs, \"\\nrelative errors (E,sd,min,max)=\", err_rel) \n",
    "\n",
    "# (IV) Do KNN regression  \n",
    "print (\"\\n#### KNN regression with flagKLinReg=\", flagKLinReg, \" ####\")\n",
    "knnr = KNNRegressifier(K)     # REPLACE dummy code: Create and fit KNNRegressifier\n",
    "knnr.fit(X,K)\n",
    "print (\"IV.1) Some predictions on the training data:\")\n",
    "for i in range(N_pred): \n",
    "    n=idx_perm[i]\n",
    "    print (\"Prediction for X[\",n,\"]=\",X[n],\" is y=\",knnr.predict(X[n],K,flagKLinReg),\", whereas true value is T[\",n,\"]=\",T[n])   # REPLACE dummy code: compute prediction for X[n]\n",
    "print (\"IV.2) Some predicitions for new test vectors:\")\n",
    "print (\"Prediction for x_test_1 is y=\", knnr.predict(x_test_1,K,flagKLinReg))    # REPLACE dummy code: compute prediction for x_test_1\n",
    "print (\"Prediction for x_test_2 is y=\", knnr.predict(x_test_2,K,flagKLinReg))    # REPLACE dummy code: compute prediction for x_test_2\n",
    "print (\"IV.3) S=\",S,\"fold Cross Validation:\")\n",
    "err_abs,err_rel = knnr.crossvalidate(S,X,T)                   # REPLACE dummy code: do cross validation!! \n",
    "print (\"absolute errors (E,sd,min,max)=\", err_abs, \"\\nrelative errors (E,sd,min,max)=\", err_rel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
